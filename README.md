# Advanced-Toxic-Comment-Classifier

üìú **Project Description**
 
The Toxic Comment Classifier is an Advanced machine-learning project developed to detect and categorize toxic content in user comments. By employing a multi-label classification strategy, it addresses the critical challenges faced by online platforms in identifying harmful language. Designed and implemented in a Jupyter Notebook environment, the project utilizes cutting-edge techniques for feature extraction and classification.
This advanced solution is deployed for real-time toxic comment detection, leveraging Convolutional Neural Networks (CNNs) and a Kaggle dataset to achieve an impressive accuracy of 95.31%. The workflow encompasses comprehensive preprocessing, feature extraction, and detailed evaluation, enabling effective identification of hate speech, harassment, and offensive language.

üéØ**Objectives**

Build a robust classifier to accurately identify toxic comments across six predefined categories:
- **Toxic**  
- **Severe Toxic** 
- **Obscene**  
- **Threat**  
- **Insult**  
- **Identity Hate**
Applying advanced preprocessing techniques and machine learning techniques  to ensure high accuracy. Additionally, analyze and provide insights into the patterns and distribution of toxic content within the dataset.

üõ†Ô∏è Tools and Technologies

-**Programming Language:** Python
-**Development Environment:** Jupyter Notebook 
-**Libraries:** Pandas, NumPy, Matplotlib, Seaborn, Scikit-learn, Tensorflow
-**Visualization Tools:** Matplotlib and Seaborn for in-depth exploratory data analysis (EDA).





